{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "from keras_self_attention import SeqSelfAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the data from the general sentence embeddings\n",
    "with open('data/sentence_embeddings/general/unsorted/sentemb/sentemb_unlabeled3.p', 'rb') as f:\n",
    "    data_general = pkl.load(f)\n",
    "\n",
    "with open('data/sentence_embeddings/general/unsorted/label_domain/label_domain_train_sentemb_unlabeled3.p', 'rb') as f:\n",
    "    temp_train = pkl.load(f)\n",
    "\n",
    "with open('data/sentence_embeddings/general/unsorted/label_domain/label_domain_test_sentemb_unlabeled3.p', 'rb') as f:\n",
    "    temp_test = pkl.load(f)\n",
    "    \n",
    "labels_general = np.hstack((temp_train, temp_test))\n",
    "\n",
    "data_general = data_general.transpose()\n",
    "\n",
    "# import all the specific sentence embedding data - here domain 0 was chosen\n",
    "with open('data/sentence_embeddings/specific/sentemb/sentemb_unlabeled3_1.p', 'rb') as f:\n",
    "    data_spec = pkl.load(f)\n",
    "    \n",
    "with open('data/sentence_embeddings/specific/label_domain/label_domain_train_sentemb_unlabeled3_1.p', 'rb') as f:\n",
    "    temp_train = pkl.load(f)\n",
    "\n",
    "with open('data/sentence_embeddings/specific/label_domain/label_domain_test_sentemb_unlabeled3_1.p', 'rb') as f:\n",
    "    temp_test = pkl.load(f)\n",
    "    \n",
    "labels_spec = np.hstack((temp_train, temp_test))\n",
    "\n",
    "data_spec = data_spec.transpose()\n",
    "labels_spec = labels_spec[0,:]\n",
    "labels_spec = labels_spec.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_spec_train[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 31753)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_general.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data 70-10-20 (train-validation-test) - data was already shuffled before\n",
    "X_train = data_general[:22227]\n",
    "X_val = data_general[22227:25402]\n",
    "X_test = data_general[25402:]\n",
    "\n",
    "\n",
    "\n",
    "labels_gen_train = labels_general[:22227]\n",
    "labels_gen_val = labels_general[22227:25402]\n",
    "labels_gen_test = labels_general[25402:]\n",
    "\n",
    "# save data\n",
    "pkl.dump(np.vstack((X_val, X_test)), open(\"data/sentence_embeddings/general/sorted/val_test/vt_data4_10_1.p\", \"wb\"))\n",
    "pkl.dump(np.hstack((labels_general[:,22227:25402],labels_general[:,25402:])), open(\"data/sentence_embeddings/general/sorted/val_test/vt_labels4_10_1.p\", \"wb\"))\n",
    "\n",
    "pkl.dump(np.vstack((X_train)), open(\"data/sentence_embeddings/general/sorted/train/train_data4_10_1.p\", \"wb\"))\n",
    "pkl.dump(np.hstack((labels_general[:,:22227])), open(\"data/sentence_embeddings/general/sorted/train/train_labels4_10_1.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the target domain\n",
    "index_spec = 1\n",
    "\n",
    "\n",
    "# importing the data for the general sentence embeddings, here corresponding data from domain 0 was chosen\n",
    "with open('data/sentence_embeddings/general/sorted/train/train_data3_10_1.p', 'rb') as f:\n",
    "    X_train_gen = pkl.load(f)\n",
    "\n",
    "with open('data/sentence_embeddings/general/sorted/train/train_labels3_10_1.p', 'rb') as f:\n",
    "    y_train = pkl.load(f)\n",
    "    \n",
    "with open('data/sentence_embeddings/general/sorted/val_test/vt_data3_10_1.p', 'rb') as f:\n",
    "    X_val_test_spec = pkl.load(f)\n",
    "\n",
    "with open('data/sentence_embeddings/general/sorted/val_test/vt_labels3_10_1.p', 'rb') as f:\n",
    "    y_val_test = pkl.load(f)\n",
    "\n",
    "labels_total = np.hstack((y_train[:,:22227], y_val_test))\n",
    "X_train_gen, X_val_gen, X_test_gen = X_train_gen[:22227], X_train_gen[:25402], X_train_gen[25402:]\n",
    "y_train, y_val, y_test = y_train[0,:22227], y_train[0,:25402], y_train[0,25402:]\n",
    "\n",
    "\n",
    "# import the data from the specific sentence embeddings, here corresponding data from domain 0 was chosen\n",
    "with open('data/sentence_embeddings/specific/sentemb/sentemb_unlabeled3_1.p', 'rb') as f:\n",
    "    X_spec = pkl.load(f)\n",
    "    \n",
    "#X_train_spec, X_val_spec, X_test_spec = X_spec[:1400], X_spec[1400:1600], X_spec[1600:2000] \n",
    "\n",
    "import numpy as np\n",
    "#X_spec=np.repeat(X_spec,repeats=3, axis=1)\n",
    "\n",
    "X_train_spec, X_val_spec, X_test_spec = X_spec.transpose()[:1400], X_spec.transpose()[1400:1600], X_spec.transpose()[1600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the proposed classifier\n",
    "\n",
    "INPUT_SIZE = 300\n",
    "LATENT_SIZE = 300\n",
    "\n",
    "# domain-general model parts\n",
    "inp_gen = tf.keras.Input(shape=(1,INPUT_SIZE))\n",
    "#inp_gen_att, attn_weights_gen = SeqSelfAttention(return_attention = True)(inp_gen)\n",
    "#layer0 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(LATENT_SIZE, input_shape=(None,1,INPUT_SIZE), return_sequences=True))\n",
    "inp_spec = tf.keras.Input(shape=(1,INPUT_SIZE))\n",
    "merged = tf.keras.layers.Concatenate()([inp_gen, inp_spec])\n",
    "merged = tf.keras.layers.Dense(300, activation='sigmoid')(merged)\n",
    "#merged2 = tf.keras.layers.Dense(100, activation='sigmoid')(merged)\n",
    "   # merged = tf.keras.layers.Dense(100, activation='sigmoid')(merged)\n",
    "# drop out layer and dense layer\n",
    "merged = tf.keras.layers.Dropout(.4)(merged)\n",
    "merged = tf.keras.layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "    \n",
    "classifier_gen = tf.keras.Model([inp_gen,inp_spec], merged)\n",
    "\n",
    "#classifier_spec =  tf.keras.Model([inp_gen,inp_spec], merged2)\n",
    "\n",
    "#inp_spec_att, attn_weights_spec = SeqSelfAttention(return_attention = True)(inp_spec)\n",
    "#out_spec = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(LATENT_SIZE, input_shape=(None,1,INPUT_SIZE)))(inp_spec)\n",
    "\n",
    "#out= inner_model(inp_spec)\n",
    "# concatenate domain-general and domain-specific results\n",
    "#merged = tf.keras.layers.Concatenate()([out_gen, out_spec])\n",
    "\n",
    "# drop out layer and dense layer\n",
    "\n",
    "#inner_model = tf.keras.Model([inp_gen], merged)\n",
    "#classifier4 = tf.keras.Model([inp_spec], out)\n",
    "#classifier4.trainable=False\n",
    "#classifier.summary()\n",
    "\n",
    "# Check that the weights of layer1 have not changed during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /usr/local/lib/python3.6/dist-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/keras/engine/training.py:787 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.6/dist-packages/keras/engine/input_spec.py:202 assert_input_compatibility\n        ' input tensors. Inputs received: ' + str(inputs))\n\n    ValueError: Layer model_1 expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 1, 300) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-76b0e4c00e3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"weights/classifier/classifier_without_al/standard_model/classifier_domain3_1.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# evaluating the general model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/keras/engine/training.py:787 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.6/dist-packages/keras/engine/input_spec.py:202 assert_input_compatibility\n        ' input tensors. Inputs received: ' + str(inputs))\n\n    ValueError: Layer model_1 expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 1, 300) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "# training the general model\n",
    "classifier_gen.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=\"weights/classifier/classifier_without_al/standard_model/classifier_domain3_1.h5\")\n",
    "history = classifier_gen.fit([np.expand_dims(X_train_gen, 1)], y_train, epochs=30, validation_data = ([np.expand_dims(X_val_gen, 1)], y_val), callbacks = [checkpoint, es], batch_size=32)\n",
    "\n",
    "# evaluating the general model\n",
    "score = classifier_gen.evaluate([np.expand_dims(X_test_gen, 1)], y_test, verbose=0) \n",
    "print('Final accuracy score: '+str(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "44/44 [==============================] - 7s 41ms/step - loss: 0.9084 - accuracy: 0.5664 - val_loss: 0.6314 - val_accuracy: 0.6800\n",
      "Epoch 2/30\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.5960 - accuracy: 0.6857 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.5281 - accuracy: 0.7536 - val_loss: 0.4840 - val_accuracy: 0.7700\n",
      "Epoch 4/30\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4913 - accuracy: 0.7714 - val_loss: 0.4512 - val_accuracy: 0.7900\n",
      "Epoch 5/30\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4538 - accuracy: 0.8043 - val_loss: 0.4416 - val_accuracy: 0.8000\n",
      "Epoch 6/30\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4365 - accuracy: 0.8014 - val_loss: 0.4325 - val_accuracy: 0.8000\n",
      "Epoch 7/30\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4153 - accuracy: 0.8086 - val_loss: 0.4262 - val_accuracy: 0.8050\n",
      "Epoch 8/30\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4024 - accuracy: 0.8264 - val_loss: 0.4326 - val_accuracy: 0.8100\n",
      "Epoch 9/30\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3926 - accuracy: 0.8321 - val_loss: 0.4240 - val_accuracy: 0.8250\n",
      "Epoch 10/30\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3824 - accuracy: 0.8343 - val_loss: 0.4224 - val_accuracy: 0.8200\n",
      "Epoch 11/30\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3746 - accuracy: 0.8321 - val_loss: 0.4254 - val_accuracy: 0.8000\n",
      "Epoch 12/30\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3750 - accuracy: 0.8364 - val_loss: 0.4342 - val_accuracy: 0.8000\n",
      "Epoch 13/30\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3757 - accuracy: 0.8307 - val_loss: 0.4281 - val_accuracy: 0.8150\n",
      "Epoch 14/30\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3685 - accuracy: 0.8414 - val_loss: 0.4481 - val_accuracy: 0.8050\n",
      "Epoch 15/30\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3600 - accuracy: 0.8443 - val_loss: 0.4440 - val_accuracy: 0.8100\n",
      "Epoch 16/30\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3664 - accuracy: 0.8321 - val_loss: 0.4451 - val_accuracy: 0.8150\n",
      "Epoch 17/30\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3525 - accuracy: 0.8393 - val_loss: 0.4528 - val_accuracy: 0.8100\n",
      "Epoch 18/30\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3602 - accuracy: 0.8407 - val_loss: 0.4398 - val_accuracy: 0.8200\n",
      "Epoch 19/30\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3517 - accuracy: 0.8450 - val_loss: 0.4399 - val_accuracy: 0.8050\n",
      "Epoch 20/30\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3510 - accuracy: 0.8407 - val_loss: 0.4351 - val_accuracy: 0.8250\n",
      "Final accuracy score: 0.8050000071525574\n"
     ]
    }
   ],
   "source": [
    "# training the specific model\n",
    "classifier4.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=\"weights/classifier/classifier_without_al/standard_model/classifier_domain2_13.h5\")\n",
    "history = classifier4.fit([np.expand_dims(X_train_spec, 1)], labels_spec_train, epochs=30, validation_data = ([np.expand_dims(X_val_spec, 1)], labels_spec_val), callbacks = [checkpoint, es], batch_size=32)\n",
    "\n",
    "# evaluating the specific model\n",
    "score = classifier4.evaluate([np.expand_dims(X_test_spec, 1)], labels_spec_test, verbose=0) \n",
    "print('Final accuracy score: '+str(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
